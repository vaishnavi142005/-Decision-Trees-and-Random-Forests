# Task 5 â€“ Decision Trees & Random Forests

## Objective
Learn and apply tree-based classification models using the Heart Disease dataset from Kaggle.

## Steps Performed
1. Loaded dataset and checked for missing values.
2. Split data into training (80%) and testing (20%) sets.
3. Trained a Decision Tree Classifier and visualized the tree.
4. Controlled overfitting using the `max_depth` parameter.
5. Trained a Random Forest Classifier and compared accuracy with the Decision Tree.
6. Visualized feature importance from the Random Forest.
7. Evaluated models using confusion matrix, classification report, and cross-validation.

## Results
- **Decision Tree Accuracy:** ~X%
- **Decision Tree (Max Depth=3) Accuracy:** ~Y%
- **Random Forest Accuracy:** ~Z%
- Random Forest showed better accuracy and stability than a single Decision Tree.

## Tools Used
Python, Pandas, NumPy, Matplotlib, Seaborn, Scikit-learn, Graphviz
